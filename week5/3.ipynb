{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "251915bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0, Loss = 2158.841808080673\n",
      "Epoch - 1, Loss = 2145.4184141159058\n",
      "Epoch - 2, Loss = 2124.737733602524\n",
      "Epoch - 3, Loss = 2085.4698164463043\n",
      "Epoch - 4, Loss = 1998.9035980701447\n",
      "Epoch - 5, Loss = 1767.7134654521942\n",
      "Epoch - 6, Loss = 1284.176250398159\n",
      "Epoch - 7, Loss = 847.8750349283218\n",
      "Epoch - 8, Loss = 613.6570642888546\n",
      "Epoch - 9, Loss = 483.20047226548195\n",
      "[[ 935    0    2    0    4   18   16    3    2    0]\n",
      " [   0 1095    0    7    0    4    2    1   26    0]\n",
      " [   7    8  846   38   17    7    9   29   63    8]\n",
      " [   0    7   26  902    0   16    0   31   24    4]\n",
      " [   4    1    0    0  885    2   36    3   19   32]\n",
      " [  14   24    3   22    6  743   32    9   29   10]\n",
      " [  27    5    1    0   51   13  849    0   12    0]\n",
      " [   4   13   45   56    1    5    0  851    3   50]\n",
      " [   0   15    8   53   12   26   19    4  784   53]\n",
      " [  14    2    3   19   31   15    4   22   15  884]]\n",
      "Number of learnable parameters: 149798\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define the transform for MNIST dataset\n",
    "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, ), (0.5, ))])\n",
    "\n",
    "# Load the dataset\n",
    "train = datasets.MNIST('.', train=True, download=True, transform=transforms)\n",
    "test = datasets.MNIST('.', train=False, download=True, transform=transforms)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Convolutional layers\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2), stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2), stride=2),\n",
    "            nn.Conv2d(128, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2), stride=2)\n",
    "        )\n",
    "        \n",
    "        # Use a dummy input to calculate the flattened size after convolutions\n",
    "        self._dummy_input = torch.zeros(1, 1, 28, 28)  # Example input (1 channel, 28x28)\n",
    "        self.flattened_size = self._get_flattened_size()\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.classify_head = nn.Sequential(\n",
    "            nn.Linear(self.flattened_size, 20, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10, bias=True)\n",
    "        )\n",
    "\n",
    "    def _get_flattened_size(self):\n",
    "        # Forward pass through the convolution layers to get the flattened size\n",
    "        x = self.net(self._dummy_input)\n",
    "        return x.numel()  # Number of elements in the output tensor\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through the convolutional layers\n",
    "        x = self.net(x)\n",
    "        \n",
    "        # Flatten the output before passing to the fully connected layers\n",
    "        x = x.view(x.size(0), -1)  # Flatten to (batch_size, flattened_size)\n",
    "        \n",
    "        # Pass through the fully connected layers\n",
    "        return self.classify_head(x)\n",
    "\n",
    "# Instantiate the model\n",
    "model = CNN()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for input, target in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        output = model(input)  # Forward pass\n",
    "        loss = criterion(output, target)  # Calculate the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update model parameters\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch - {epoch}, Loss = {running_loss}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for input, target in test_loader:\n",
    "        output = model(input)\n",
    "        val, index = torch.max(output, 1)\n",
    "        all_preds.extend(index.cpu().numpy())\n",
    "        all_labels.extend(target.cpu().numpy())\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(cm)\n",
    "\n",
    "# Print the number of learnable parameters\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Number of learnable parameters: {num_params}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e986e4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
